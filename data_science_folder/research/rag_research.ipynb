{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text2SQL RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import openai\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import Document, SummaryIndex, ListIndex, SQLDatabase, ServiceContext\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from sqlalchemy import create_engine\n",
    "from typing import List\n",
    "import ast\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create SQLlite Database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite database created and CSV data imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load CSV files into Pandas DataFrames\n",
    "file1 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/hourly_agg_weather_flavoured_features.csv'\n",
    "file2 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/hourly_orders_weather_flavoured.csv'\n",
    "file3 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rfm_data.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "df3 = pd.read_csv(file3)\n",
    "\n",
    "# Create SQLite database and establish connection\n",
    "conn = sqlite3.connect('/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rag_demo_database.db')\n",
    "\n",
    "# Write the dataframes to SQLite tables\n",
    "df1.to_sql('hourly_agg_weather_ecommerce_KPIs', conn, if_exists='replace', index=False)\n",
    "df2.to_sql('hourly_orders_customer_main_table', conn, if_exists='replace', index=False)\n",
    "df3.to_sql('rfm_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"SQLite database created and CSV data imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Script Building__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite database created and CSV data imported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/f3yrmbzn2jq1rcxqy582qldm0000gn/T/ipykernel_46314/1233678511.py:28: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: Get the customer segments based on the RFM analysis.\n",
      "Generated Questions: 1. Retrieve the customer segments based on the RFM analysis., 2. What are the characteristics of customers in the \"High-Value\" segment?\n",
      "Selected Tables: ['rfm_data']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Engine' object has no attribute 'get_single_table_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 119\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m    118\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet the customer segments based on the RFM analysis.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msql_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[10], line 99\u001b[0m, in \u001b[0;36msql_rag\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     91\u001b[0m sql_query_engine \u001b[38;5;241m=\u001b[39m NLSQLTableQueryEngine(\n\u001b[1;32m     92\u001b[0m     sql_database\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m     93\u001b[0m     tables\u001b[38;5;241m=\u001b[39mselected_tables,\n\u001b[1;32m     94\u001b[0m     synthesize_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# synthesize_response is set to False to return the raw SQL query\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Execute the SQL query\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m sql_response \u001b[38;5;241m=\u001b[39m \u001b[43msql_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_to_sql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Debugging output\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQL Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:146\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_drop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:98\u001b[0m, in \u001b[0;36mDispatcher.span_drop\u001b[0;34m(self, id_, bound_args, instance, err, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m c:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m c\u001b[38;5;241m.\u001b[39mspan_handlers:\n\u001b[0;32m---> 98\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_drop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mid_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n\u001b[1;32m    107\u001b[0m         c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/instrumentation/span_handlers/base.py:77\u001b[0m, in \u001b[0;36mBaseSpanHandler.span_drop\u001b[0;34m(self, id_, bound_args, instance, err, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspan_drop\u001b[39m(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;241m*\u001b[39margs: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Logic for dropping a span i.e. early exit.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_to_drop_span\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m span:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_span_id \u001b[38;5;241m==\u001b[39m id_:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/instrumentation/span_handlers/null.py:71\u001b[0m, in \u001b[0;36mNullSpanHandler.prepare_to_drop_span\u001b[0;34m(self, id_, bound_args, instance, err, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Logic for droppping a span.\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/instrumentation/dispatcher.py:144\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_drop(id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, err\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/base/base_query_engine.py:51\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     50\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 51\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(QueryEndEvent())\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/indices/struct_store/sql_query.py:366\u001b[0m, in \u001b[0;36mBaseSQLTableQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     retrieved_nodes, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_with_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_bundle\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     sql_query_str \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql_query\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synthesize_response:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/indices/struct_store/sql_retriever.py:291\u001b[0m, in \u001b[0;36mNLSQLRetriever.retrieve_with_metadata\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     query_bundle \u001b[38;5;241m=\u001b[39m str_or_query_bundle\n\u001b[0;32m--> 291\u001b[0m table_desc_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_table_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Table desc str: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_desc_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/llama_index/core/indices/struct_store/sql_retriever.py:397\u001b[0m, in \u001b[0;36mNLSQLRetriever._get_table_context\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    394\u001b[0m     context_strs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_str_prefix]\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_schema_obj \u001b[38;5;129;01min\u001b[39;00m table_schema_objs:\n\u001b[0;32m--> 397\u001b[0m     table_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sql_database\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_table_info\u001b[49m(\n\u001b[1;32m    398\u001b[0m         table_schema_obj\u001b[38;5;241m.\u001b[39mtable_name\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m table_schema_obj\u001b[38;5;241m.\u001b[39mcontext_str:\n\u001b[1;32m    402\u001b[0m         table_opt_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The table description is: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Engine' object has no attribute 'get_single_table_info'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load CSV files into Pandas DataFrames\n",
    "file1 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/hourly_agg_weather_flavoured_features.csv'\n",
    "file2 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/hourly_orders_weather_flavoured.csv'\n",
    "file3 = '/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rfm_data.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "df3 = pd.read_csv(file3)\n",
    "\n",
    "# Create SQLite database and establish connection\n",
    "conn = sqlite3.connect('/Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rag_demo_database.db')\n",
    "\n",
    "# Write the dataframes to SQLite tables\n",
    "df1.to_sql('hourly_agg_weather_ecommerce_KPIs', conn, if_exists='replace', index=False)\n",
    "df2.to_sql('hourly_orders_customer_main_table', conn, if_exists='replace', index=False)\n",
    "df3.to_sql('rfm_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"SQLite database created and CSV data imported successfully.\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = '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'  # demo_rag to be stored in .env file\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "def generate_questions(user_query: str) -> List[str]:\n",
    "    system_message = f'''\n",
    "    You are given SQLite tables with the following name and columns.\n",
    "    \n",
    "      1. hourly_agg_weather_ecommerce_KPIs: {', '.join(df1.columns)}\n",
    "      2. hourly_orders_customer_main_table: {', '.join(df2.columns)}\n",
    "      3. rfm_data: {', '.join(df3.columns)}\n",
    "    \n",
    "    Your task is to decompose the given question into the following two questions.\n",
    "    \n",
    "    1. Question in natural language that needs to be asked to retrieve results from the table.\n",
    "    2. Question that needs to be asked on top of the result from the first question to provide the final answer.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    Input:\n",
    "    What was my top best month in 2023 in terms of revenue?\n",
    "    \n",
    "    Output:\n",
    "    1. Get the month with the highest revenue in 2023\n",
    "    2. Provide the monthly revenue for the month of January 2023\n",
    "    '''\n",
    "    \n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", content=system_message),\n",
    "        ChatMessage(role=\"user\", content=user_query),\n",
    "    ]\n",
    "    generated_questions = llm.chat(messages).message.content.split('\\n')\n",
    "    \n",
    "    return generated_questions\n",
    "\n",
    "def determine_tables(user_query: str) -> List[str]:\n",
    "    table_mapping = {\n",
    "        'weather': 'hourly_agg_weather_ecommerce_KPIs',\n",
    "        'orders': 'hourly_orders_customer_main_table',\n",
    "        'rfm': 'rfm_data'\n",
    "    }\n",
    "    \n",
    "    selected_tables = []\n",
    "    for keyword, table in table_mapping.items():\n",
    "        if keyword in user_query.lower():\n",
    "            selected_tables.append(table)\n",
    "    \n",
    "    return selected_tables\n",
    "\n",
    "def sql_rag(user_query: str) -> str:\n",
    "    text_to_sql_query, rag_query = generate_questions(user_query)\n",
    "    \n",
    "    selected_tables = determine_tables(user_query)\n",
    "    \n",
    "    # Debugging output\n",
    "    print(f\"User Query: {user_query}\")\n",
    "    print(f\"Generated Questions: {text_to_sql_query}, {rag_query}\")\n",
    "    print(f\"Selected Tables: {selected_tables}\")\n",
    "\n",
    "    if not selected_tables:\n",
    "        return \"No relevant tables found for the query.\"\n",
    "\n",
    "    sql_database_url = \"sqlite:///Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rag_demo_database.db\"\n",
    "    engine = create_engine(sql_database_url)\n",
    "    \n",
    "    sql_query_engine = NLSQLTableQueryEngine(\n",
    "        sql_database=engine,\n",
    "        tables=selected_tables,\n",
    "        synthesize_response=False,  # synthesize_response is set to False to return the raw SQL query\n",
    "        service_context=service_context\n",
    "    )\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    sql_response = sql_query_engine.query(text_to_sql_query)\n",
    "    \n",
    "    # Debugging output\n",
    "    print(f\"SQL Response: {sql_response}\")\n",
    "\n",
    "    # Processing the SQL response\n",
    "    sql_response_list = ast.literal_eval(sql_response.response)\n",
    "    text = [' '.join(t) for t in sql_response_list]\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    # Refining and Interpreting the reviews with ListIndex\n",
    "    listindex = ListIndex([Document(text=text)])\n",
    "    list_query_engine = listindex.as_query_engine()\n",
    "\n",
    "    response = list_query_engine.query(rag_query)\n",
    "\n",
    "    return response.response\n",
    "\n",
    "# Example usage\n",
    "user_query = \"Get the customer segments based on the RFM analysis.\"\n",
    "result = sql_rag(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decomposition of user query__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries from llama index\n",
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "from llama_index import Document, SummaryIndex\n",
    "from llama_index import SQLDatabase, ServiceContext\n",
    "from llama_index.llms import ChatMessage, OpenAI\n",
    "from typing import List\n",
    "import ast\n",
    "import openai\n",
    "\n",
    "# set llm\n",
    "openai.api_key = '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'\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "def generate_questions(user_query: str) -> list[str]:\n",
    "  system_message = f'''\n",
    "  You are given with SQLite tables with the following name and columns.\n",
    "\n",
    "    1. hourly_agg_weather_ecommerce_KPIs: {', '.join(df1.columns)}\n",
    "    2. hourly_orders_customer_main_table: {', '.join(df2.columns)}\n",
    "    3. rfm_data: {', '.join(df3.columns)}\n",
    "\n",
    "  Your task is to decompose the given question into the following two questions.\n",
    "\n",
    "  1. Question in natural language that needs to be asked to retrieve results from the table.\n",
    "  2. Question that needs to be asked on the top of the result from the first question to provide the final answer.\n",
    "\n",
    "  Example:\n",
    "\n",
    "  Input:\n",
    "  How is the culture of countries whose population is more than 5000000\n",
    "\n",
    "  Output:\n",
    "  1. Get the reviews of countries whose population is more than 5000000\n",
    "  2. Provide the culture of countries\n",
    "  '''\n",
    "\n",
    "  messages = [\n",
    "      ChatMessage(role=\"system\", content=system_message),\n",
    "      ChatMessage(role=\"user\", content=user_query),\n",
    "  ]\n",
    "  generated_questions = llm.chat(messages).message.content.split('\\n')\n",
    "\n",
    "  return generated_questions\n",
    "\n",
    "user_query = \"Get the summary of reviews of Iphone13\"\n",
    "\n",
    "text_to_sql_query, rag_query = generate_questions(user_query)\n",
    "\n",
    "sql_database = \"sqlite:///Users/lucazosso/Desktop/IE_Course/weclomeback/welcomeback_dev/data_science_folder/cleaned/rag_demo_database.db\"\n",
    "tables = #We specify which table(s) our query will be run against, this shouldbe dynamic based on the user input\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=,###,\n",
    "    synthesize_response=False, #synthesize_response is set to False to return the raw SQL query\n",
    "    service_context=service_context #service_context, This is an optional parameter, which could be used to provide service-specific settings or plugins.\n",
    ")\n",
    "\n",
    "#Execute the SQL query\n",
    "sql_response = sql_query_engine.query(text_to_sql_query)\n",
    "\n",
    "\n",
    "# Processing the SQL response\n",
    "sql_response_list = ast.literal_eval(sql_response.response)\n",
    "text = [' '.join(t) for t in sql_response_list]\n",
    "text = ' '.join(text)\n",
    "\n",
    "# Refining and Interpreting the reviews with ListIndex:\n",
    "'''After obtaining the primary set of results from the SQL query, \n",
    "there are often situations where further refinement or interpretation is required. \n",
    "This is where ListIndex from LlamaIndex plays a crucial role. \n",
    "It allows us to execute the secondary question on our obtained text data to get a refined answer.\n",
    "'''\n",
    "\n",
    "listindex = ListIndex([Document(text=text)])\n",
    "list_query_engine = listindex.as_query_engine()\n",
    "\n",
    "response = list_query_engine.query(rag_query)\n",
    "\n",
    "print(response.response)\n",
    "\n",
    "# Everything Wrap up into a function\n",
    "\"\"\"Function to perform SQL+RAG\"\"\"\n",
    "\n",
    "def sql_rag(user_query: str) -> str:\n",
    "  text_to_sql_query, rag_query = generate_questions(user_query)\n",
    "\n",
    "  sql_response = sql_query_engine.query(text_to_sql_query)\n",
    "\n",
    "  sql_response_list = ast.literal_eval(sql_response.response)\n",
    "\n",
    "  text = [' '.join(t) for t in sql_response_list]\n",
    "  text = ' '.join(text)\n",
    "\n",
    "  listindex = ListIndex([Document(text=text)])\n",
    "  list_query_engine = listindex.as_query_engine()\n",
    "\n",
    "  summary = list_query_engine.query(rag_query)\n",
    "\n",
    "  return summary.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arm64\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(platform.machine())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
